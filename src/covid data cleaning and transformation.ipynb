{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d780e91e-6472-4164-bcdf-84341fd885eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Import data\n",
    "\n",
    "## Local Files\n",
    "\n",
    "List the datasets available on the Databricks filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b82440fb-73ad-4424-be18-88193d5153a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[74]: [FileInfo(path='dbfs:/FileStore/tables/demographics.csv', name='demographics.csv', size=1544607, modificationTime=1700869951000),\n FileInfo(path='dbfs:/FileStore/tables/economy.csv', name='economy.csv', size=10228, modificationTime=1700868829000),\n FileInfo(path='dbfs:/FileStore/tables/epidemiology.csv', name='epidemiology.csv', size=520931512, modificationTime=1700870705000),\n FileInfo(path='dbfs:/FileStore/tables/geography.csv', name='geography.csv', size=1005065, modificationTime=1700869953000),\n FileInfo(path='dbfs:/FileStore/tables/government_response.csv', name='government_response.csv', size=17676542, modificationTime=1700869979000),\n FileInfo(path='dbfs:/FileStore/tables/health.csv', name='health.csv', size=122072, modificationTime=1700869980000),\n FileInfo(path='dbfs:/FileStore/tables/mobility.csv', name='mobility.csv', size=234579795, modificationTime=1700870325000),\n FileInfo(path='dbfs:/FileStore/tables/vaccination_access.csv', name='vaccination_access.csv', size=743122627, modificationTime=1700871382000),\n FileInfo(path='dbfs:/FileStore/tables/vaccinations.csv', name='vaccinations.csv', size=164305510, modificationTime=1700870943000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls('FileStore/tables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ee81ad4-7008-4cb9-b74d-40fdb0ada9b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Read Files\n",
    "\n",
    "The datasets are read as CSV files, for which the first row of each provides column headers. The data types held by each column is inferred from the non-null values it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "070f4df4-fe57-4b21-9025-0028da9749ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "demographics = spark.read.option('header', True).option('delimiter', ',').option('inferSchema', True).csv('/FileStore/tables/demographics.csv')\n",
    "economy = spark.read.option('header', True).option('delimiter', ',').option('inferSchema', True).csv('/FileStore/tables/economy.csv')\n",
    "epidemiology = spark.read.option('header', True).option('delimiter', ',').option('inferSchema', True).csv('/FileStore/tables/epidemiology.csv')\n",
    "geography = spark.read.option('header', True).option('delimiter', ',').option('inferSchema', True).csv('/FileStore/tables/geography.csv')\n",
    "government_response = spark.read.option('header', True).option('delimiter', ',').option('inferSchema', True).csv('/FileStore/tables/government_response.csv')\n",
    "health = spark.read.option('header', True).option('delimiter', ',').option('inferSchema', True).csv('/FileStore/tables/health.csv')\n",
    "mobility = spark.read.option('header', True).option('delimiter', ',').option('inferSchema', True).csv('/FileStore/tables/mobility.csv')\n",
    "# TODO remove this.\n",
    "vaccination_access = spark.read.option('header', True).option('delimiter', ',').option('inferSchema', True).csv('/FileStore/tables/vaccination_access.csv')\n",
    "vaccinations = spark.read.option('header', True).option('delimiter', ',').option('inferSchema', True).csv('/FileStore/tables/vaccinations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b38c38ca-f971-4ece-9617-0f1a0bd285af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Cleaning and Transformation\n",
    "\n",
    "## Demographics\n",
    "\n",
    "For every dataset, we keep only rows that specify countries (not regions therein). We characterize a population as 'young', 'mid', or 'old' based on the number of people who belong to each of a set of age ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "727e3b87-4ee3-4b09-9ebb-576b0570694f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from itertools import chain\n",
    "from operator import add\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql.functions import col, create_map, greatest, lit, max, posexplode\n",
    "\n",
    "demographics = demographics.filter('location_key NOT LIKE \"%\\_%\"')\n",
    "\n",
    "demographics_imputer_columns = list(set(demographics.columns).difference(['location_key']))\n",
    "demographics_imputer = Imputer(inputCols=demographics_imputer_columns, outputCols=demographics_imputer_columns)\n",
    "demographics = demographics_imputer.fit(demographics).transform(demographics)\n",
    "\n",
    "young_columns = ['population_age_00_09', 'population_age_10_19', 'population_age_20_29']\n",
    "mid_columns = ['population_age_30_39', 'population_age_40_49', 'population_age_50_59']\n",
    "old_columns = ['population_age_60_69', 'population_age_70_79', 'population_age_80_and_older']\n",
    "\n",
    "demographics = demographics.withColumn('young', reduce(add, [col(x) for x in young_columns])) \\\n",
    "                           .withColumn('mid', reduce(add, [col(x) for x in mid_columns])) \\\n",
    "                           .withColumn('old', reduce(add, [col(x) for x in old_columns])) \\\n",
    "                           .drop(*(young_columns + mid_columns + old_columns))\n",
    "\n",
    "demographics = demographics.withColumn('max_value', greatest('young', 'mid', 'old')) \\\n",
    "                           .select('*', posexplode(create_map(list(chain(*[(lit(c), col(c)) for c in demographics.columns]))))) \\\n",
    "                           .filter('max_value = value') \\\n",
    "                           .select(demographics.columns + [col('key').alias('population_age')]) \\\n",
    "                           .drop(*['young', 'mid', 'old'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be200a73-dc38-4b4e-bae1-1bbf31ab8918",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Economy\n",
    "\n",
    "Locations finer than country are once again filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e375cec-a153-4921-abed-78a398a29a4b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "economy = economy.filter('location_key NOT LIKE \"%\\_%\"')\n",
    "\n",
    "economy_imputer_columns = list(set(economy.columns).difference(['location_key']))\n",
    "economy_imputer = Imputer(inputCols=economy_imputer_columns, outputCols=economy_imputer_columns)\n",
    "economy = economy_imputer.fit(economy).transform(economy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aa276ff-b6fe-412f-9527-cdf31c30796f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Epidemiology\n",
    "\n",
    "We aggregate time series data by average or maximum according to whether the input data is a daily measure or a cumulative one respectively. From each aggregate, we determine the percentage of the associated population that it constitutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4696664a-bd91-446b-ac0c-ced45490d4f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "epidemiology = epidemiology.filter('location_key NOT LIKE \"%\\_%\"')\n",
    "\n",
    "epidemiology = epidemiology.groupBy('location_key') \\\n",
    "                           .agg(avg('new_confirmed'), avg('new_deceased'), avg('new_recovered'), avg('new_tested'), \\\n",
    "                                max('cumulative_confirmed'), max('cumulative_deceased'), max('cumulative_recovered'), max('cumulative_tested'))\n",
    "\n",
    "epidemiology = epidemiology.join(demographics.select('location_key', 'population'), on='location_key', how='fullouter') \\\n",
    "                             .withColumn('percentage_new_confirmed', col('avg(new_confirmed)') / col('population')) \\\n",
    "                             .withColumn('percentage_new_deceased', col('avg(new_deceased)') / col('population')) \\\n",
    "                             .withColumn('percentage_new_recovered', col('avg(new_recovered)') / col('population')) \\\n",
    "                             .withColumn('percentage_new_tested', col('avg(new_tested)') / col('population')) \\\n",
    "                             .withColumn('percentage_cumulative_confirmed', col('max(cumulative_confirmed)') / col('population')) \\\n",
    "                             .withColumn('percentage_cumulative_deceased', col('max(cumulative_deceased)') / col('population')) \\\n",
    "                             .withColumn('percentage_cumulative_recovered', col('max(cumulative_recovered)') / col('population')) \\\n",
    "                             .withColumn('percentage_cumulative_tested', col('max(cumulative_tested)') / col('population')) \\\n",
    "                             .drop('avg(new_confirmed)', \\\n",
    "                                   'avg(new_deceased)', \\\n",
    "                                   'avg(new_recovered)', \\\n",
    "                                   'avg(new_tested)', \\\n",
    "                                   'max(cumulative_confirmed)', \\\n",
    "                                   'max(cumulative_deceased)', \\\n",
    "                                   'max(cumulative_recovered)', \\\n",
    "                                   'max(cumulative_tested)', \\\n",
    "                                   'population')\n",
    "\n",
    "epidemiology_imputer_columns = list(set(epidemiology.columns).difference(['location_key']))\n",
    "epidemiology_imputer = Imputer(inputCols=epidemiology_imputer_columns, outputCols=epidemiology_imputer_columns)\n",
    "epidemiology = epidemiology_imputer.fit(epidemiology).transform(epidemiology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f62a2fc-37a8-4a2f-a81c-c8b28a24bf28",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Geography\n",
    "\n",
    "We remove an unecessary column, and replace absolute measures of rural and urban area with percentages of total area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dc2fa71-6c4a-4876-834a-26b6f280676a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "geography = geography.filter('location_key NOT LIKE \"%\\_%\"')\n",
    "\n",
    "geography = geography.drop('openstreetmap_id')\n",
    "\n",
    "# TODO remove these keys from other datasets.\n",
    "\n",
    "geography = geography.filter('location_key NOT IN (\"IO\", \"SJ\", \"MC\", \"VA\")')\n",
    "\n",
    "geography = geography.withColumn('percentage_area_rural_sq_km', col('area_rural_sq_km') / col('area_sq_km')) \\\n",
    "                     .withColumn('percentage_area_urban_sq_km', col('area_urban_sq_km') / col('area_sq_km')) \\\n",
    "                     .drop('area_rural_sq_km', 'area_urban_sq_km')\n",
    "\n",
    "geography_imputer_columns = list(set(geography.columns).difference(['location_key']))\n",
    "geography_imputer = Imputer(inputCols=geography_imputer_columns, outputCols=geography_imputer_columns)\n",
    "geography = geography_imputer.fit(geography).transform(geography)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14e6635-6eb4-4cde-9f7d-acada75c67e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Government Response\n",
    "\n",
    "Time series data over ordinal scaled features are aggregated with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c3852a-19f6-4c71-b0b1-69f8aa928767",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mode, when\n",
    "\n",
    "government_response = government_response.filter('location_key NOT LIKE \"%\\_%\"')\n",
    "\n",
    "government_response = government_response.groupBy('location_key') \\\n",
    "                                         .agg(mode('school_closing').alias('school_closing_severity'), \\\n",
    "                                              mode('workplace_closing').alias('workplace_closing_severity'), \\\n",
    "                                              mode('cancel_public_events').alias('cancel_public_events_severity'), \\\n",
    "                                              mode('restrictions_on_gatherings').alias('restrictions_on_gatherings_severity'), \\\n",
    "                                              mode('public_transport_closing').alias('public_transport_closing_severity'), \\\n",
    "                                              mode('stay_at_home_requirements').alias('stay_at_home_requirements_severity'), \\\n",
    "                                              mode('restrictions_on_internal_movement').alias('restrictions_on_internal_movement_severity'), \\\n",
    "                                              mode('international_travel_controls').alias('international_travel_controls_severity'), \\\n",
    "                                              mode('debt_relief').alias('debt_relief_extent'), \\\n",
    "                                              mode('public_information_campaigns').alias('public_information_campaigns_extent'), \\\n",
    "                                              mode('testing_policy').alias('testing_policy_severity'), \\\n",
    "                                              mode('contact_tracing').alias('contact_tracing_severity'), \\\n",
    "                                              mode('facial_coverings').alias('facial_coverings_severity'), \\\n",
    "                                              mode('vaccination_policy').alias('vaccination_policy_extent'))\n",
    "\n",
    "government_response_imputer_columns = list(set(government_response.columns).difference(['location_key']))\n",
    "government_response_imputer = Imputer(\n",
    "     strategy='mode', inputCols=government_response_imputer_columns, outputCols=government_response_imputer_columns)\n",
    "government_response = government_response_imputer.fit(government_response).transform(government_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdb5adfa-1ba4-4eeb-8953-6663c4d879ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Health\n",
    "\n",
    "The only transformation applied is to infer missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e43b2dd9-5e29-4e7d-a104-973707d199dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "health = health.filter('location_key NOT LIKE \"%\\_%\"')\n",
    "\n",
    "health_imputer_columns = list(set(health.columns).difference(['location_key']))\n",
    "health_imputer = Imputer(inputCols=health_imputer_columns, outputCols=health_imputer_columns)\n",
    "health = health_imputer.fit(health).transform(health)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3590bf83-90bc-44a1-b894-269d19348c74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Mobility\n",
    "\n",
    "We aggregate time series data with average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94c4bc18-21a9-4d6c-9da4-c4dcabbbfa0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mobility = mobility.filter('location_key NOT LIKE \"%\\_%\"')\n",
    "\n",
    "mobility = mobility.groupBy('location_key') \\\n",
    "                   .agg(avg('mobility_retail_and_recreation').alias('retail_and_recreation'), \\\n",
    "                        avg('mobility_grocery_and_pharmacy').alias('grocery_and_pharmacy'), \\\n",
    "                        avg('mobility_parks').alias('parks'), \\\n",
    "                        avg('mobility_transit_stations').alias('transit_stations'), \\\n",
    "                        avg('mobility_workplaces').alias('workplaces'), \\\n",
    "                        avg('mobility_residential').alias('residential'))\n",
    "\n",
    "mobility_imputer_columns = list(set(mobility.columns).difference(['location_key']))\n",
    "mobility_imputer = Imputer(inputCols=mobility_imputer_columns, outputCols=mobility_imputer_columns)\n",
    "mobility = mobility_imputer.fit(mobility).transform(mobility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "411e0058-1f95-4cff-8b01-10b7ad92a49f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Vaccinations\n",
    "\n",
    "We select a small subset of the features from this dataset, and aggregate values by the same method described under epidemiology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9b2af96-2491-4e93-8d67-a1a8ba1ba4f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vaccinations = vaccinations.filter('location_key NOT LIKE \"%\\_%\"')\n",
    "\n",
    "vaccinations = vaccinations.groupBy('location_key') \\\n",
    "                           .agg(avg('new_persons_vaccinated'), \\\n",
    "                                avg('new_persons_fully_vaccinated'), \\\n",
    "                                max('cumulative_persons_vaccinated'), \\\n",
    "                                max('cumulative_persons_fully_vaccinated'))  \n",
    "\n",
    "vaccinations = vaccinations.join(demographics.select(['location_key', 'population']), on='location_key', how='fullouter') \\\n",
    "                                             .withColumn('percentage_new_persons_vaccinated', col('avg(new_persons_vaccinated)') / col('population')) \\\n",
    "                                             .withColumn('percentage_new_persons_fully_vaccinated', col('avg(new_persons_fully_vaccinated)') / col('population')) \\\n",
    "                                             .withColumn('percentage_cumulative_persons_vaccinated', col('max(cumulative_persons_vaccinated)') / col('population')) \\\n",
    "                                             .withColumn('percentage_cumulative_persons_fully_vaccinated', col('max(cumulative_persons_fully_vaccinated)') / col('population')) \\\n",
    "                                             .drop('avg(new_persons_vaccinated)', \\\n",
    "                                                   'avg(new_persons_fully_vaccinated)', \\\n",
    "                                                   'max(cumulative_persons_vaccinated)', \\\n",
    "                                                   'max(cumulative_persons_fully_vaccinated)', \\\n",
    "                                                   'population')\n",
    "\n",
    "vaccinations_imputer_columns = list(set(vaccinations.columns).difference(['location_key']))\n",
    "vaccinations_imputer = Imputer(inputCols=vaccinations_imputer_columns, outputCols=vaccinations_imputer_columns)\n",
    "vaccinations = vaccinations_imputer.fit(vaccinations).transform(vaccinations)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "covid data cleaning and transformation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
